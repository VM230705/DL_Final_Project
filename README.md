# TimeXer å¤šå°ºåº¦æ™‚é–“åºåˆ—é æ¸¬æ¨¡å‹ - å®Œæ•´å¯¦é©—èˆ‡æ¶æ§‹åˆ†æ

## ğŸ“‹ ç›®éŒ„
- [ğŸ¯ ç ”ç©¶å‹•æ©Ÿèˆ‡æ ¸å¿ƒå‰µæ–°](#-ç ”ç©¶å‹•æ©Ÿèˆ‡æ ¸å¿ƒå‰µæ–°)
- [ğŸ—ï¸ å¤šå°ºåº¦æ¶æ§‹è¨­è¨ˆ](#ï¸-å¤šå°ºåº¦æ¶æ§‹è¨­è¨ˆ)
- [ğŸ”§ å››ç¨®èåˆç­–ç•¥è©³è§£](#-å››ç¨®èåˆç­–ç•¥è©³è§£)
- [ğŸ“Š å®Œæ•´å¯¦é©—çµæœåˆ†æ](#-å®Œæ•´å¯¦é©—çµæœåˆ†æ)
- [âš™ï¸ æ¶æ§‹å¯¦ä½œç´°ç¯€](#ï¸-æ¶æ§‹å¯¦ä½œç´°ç¯€)
- [ğŸ¯ éƒ¨ç½²å»ºè­°èˆ‡ç¸½çµ](#-éƒ¨ç½²å»ºè­°èˆ‡ç¸½çµ)

---

## ğŸ¯ ç ”ç©¶å‹•æ©Ÿèˆ‡æ ¸å¿ƒå‰µæ–°

### å•é¡Œç™¼ç¾èˆ‡è§£æ±ºæ–¹æ¡ˆ

**æ ¸å¿ƒå•é¡Œ**ï¼šå‚³çµ±TimeXerä½¿ç”¨å›ºå®špatch size 16ï¼Œç„¡æ³•é©æ‡‰ä¸åŒæ•¸æ“šé›†çš„å¤šå°ºåº¦æ™‚é–“æ¨¡å¼

**å‰µæ–°è§£æ±ºæ–¹æ¡ˆ**ï¼š
- ğŸ” **å¤šå°ºåº¦è£œä¸è¼¸å…¥**ï¼šåŒæ™‚ä½¿ç”¨patch sizes **8ã€16ã€24**
- ğŸš€ **å››ç¨®æ™ºèƒ½èåˆ**ï¼šHierarchicalã€Attentionã€Gatedã€Concat
- ğŸ¯ **è‡ªé©æ‡‰å­¸ç¿’**ï¼šæ ¹æ“šæ•¸æ“šç‰¹æ€§è‡ªå‹•å­¸ç¿’æœ€ä½³å°ºåº¦çµ„åˆ

### æ–¹æ³•æ ¸å¿ƒå‰µæ–°é»

1. **ä¸‰å°ºåº¦è£œä¸åµŒå…¥**ï¼š
   - Patch Size 8ï¼šæ•æ‰ç´°ç²’åº¦çŸ­æœŸæ³¢å‹•
   - Patch Size 16ï¼šå¹³è¡¡ç´°ç¯€èˆ‡è¶¨å‹¢ï¼ˆåŸå§‹æœ€ä½³é…ç½®ï¼‰
   - Patch Size 24ï¼šæ•æ‰é•·æœŸè¶¨å‹¢å’Œå­£ç¯€æ€§æ¨¡å¼

2. **å››ç¨®èåˆç­–ç•¥**ï¼š
   - **Hierarchical Fusion**ï¼šéšå±¤å¼æ¼¸é€²èåˆï¼Œæœ€ä½³MAEæ€§èƒ½
   - **Attention Fusion**ï¼šè·¨å°ºåº¦æ³¨æ„åŠ›æ©Ÿåˆ¶ï¼Œæœ€ä½³MSEæ€§èƒ½
   - **Gated Fusion**ï¼šé–€æ§åŠ æ¬Šèåˆï¼Œå¹³è¡¡æ€§èƒ½èˆ‡æ•ˆç‡
   - **Concat Fusion**ï¼šç›´æ¥æ‹¼æ¥ï¼Œæœ€ä½è¨ˆç®—æˆæœ¬

---

## ğŸ—ï¸ å¤šå°ºåº¦æ¶æ§‹è¨­è¨ˆ

### MultiScaleEnEmbedding æ ¸å¿ƒæ¶æ§‹
![alt text](image.png)
```mermaid
flowchart TD
    subgraph Input["ğŸ“¥ è¼¸å…¥è™•ç†"]
        TS["æ™‚é–“åºåˆ—è¼¸å…¥<br/>[B, C, L]"]
        EXO["å¤–ç”Ÿè®Šæ•¸è¼¸å…¥"]
    end
    
    subgraph MSE["ğŸ¯ MultiScaleEnEmbedding"]
        subgraph Patching["å¤šå°ºåº¦è£œä¸åˆ†å‰²"]
            P8["Patch_8<br/>12å€‹patches"]
            P16["Patch_16<br/>6å€‹patches"] 
            P24["Patch_24<br/>4å€‹patches"]
        end
        
        subgraph Embedding["æ¯å°ºåº¦ç·šæ€§åµŒå…¥"]
            E8["Linear(8 â†’ d_model)<br/>+ Position Embedding"]
            E16["Linear(16 â†’ d_model)<br/>+ Position Embedding"]
            E24["Linear(24 â†’ d_model)<br/>+ Position Embedding"]
        end
        
        subgraph Tokens["å°ºåº¦ç‰¹å®šå…¨å±€æ¨™è¨˜"]
            G8["Global Token<br/>Patch_8"]
            G16["Global Token<br/>Patch_16"]
            G24["Global Token<br/>Patch_24"]
        end
        
        subgraph Fusion["ğŸ”„ Scale Fusion Module"]
            HIER["Hierarchical Fusion"]
            ATT["Attention Fusion"]
            GATE["Gated Fusion"]
            CONCAT["Concat Fusion"]
        end
    end
    
    subgraph Encoder["ğŸ”§ Transformer Encoder"]
        SELF["Self-Attention"]
        CROSS["Exogenous-to-Endogenous<br/>Cross-Attention"]
        FFN["Feed-Forward"]
        NORM["LayerNorm"]
    end
    
    subgraph Output["ğŸ“¤ è¼¸å‡ºå±¤"]
        PROJ["Projection"]
        PRED["é æ¸¬çµæœ"]
    end
    
    TS --> Patching
    EXO --> Encoder
    
    P8 --> E8 --> G8
    P16 --> E16 --> G16  
    P24 --> E24 --> G24
    
    G8 --> Fusion
    G16 --> Fusion
    G24 --> Fusion
    
    Fusion --> SELF
    SELF --> NORM
    NORM --> CROSS
    CROSS --> NORM
    NORM --> FFN
    FFN --> NORM
    NORM --> PROJ
    PROJ --> PRED
    
    style MSE fill:#ffeb3b
    style Fusion fill:#e8f5e8
    style Encoder fill:#e3f2fd
```

### Tokenæ•¸é‡è®ŠåŒ–åˆ†æ

| æ¶æ§‹æ¨¡å¼ | Patch Sizes | Patchæ•¸é‡ | Global Tokens | ç¸½Tokenæ•¸ |
|---------|-------------|-----------|---------------|-----------|
| **åŸå§‹Single-Scale** | [16] | 6 | 1 | **7** |
| **æˆ‘å€‘çš„Multi-Scale** | [8,16,24] | 12+6+4=22 | 3 | **25** |

**é—œéµå„ªå‹¢**ï¼šTransformerè™•ç†æ›´è±å¯Œçš„åºåˆ—è¡¨ç¤ºï¼ˆ25 vs 7 tokensï¼‰ï¼Œæ•æ‰å¤šå°ºåº¦æ™‚é–“æ¨¡å¼

---

## ğŸ”§ å››ç¨®èåˆç­–ç•¥è©³è§£

### 1. ğŸ† Hierarchical Fusion (éšå±¤å¼èåˆ)

```python
def _hierarchical_fusion(self, scale_embeddings, batch_size, n_vars):
    """æ¼¸é€²å¼èåˆç­–ç•¥ - é€æ­¥æ•´åˆä¸åŒå°ºåº¦ç‰¹å¾µ"""
    fused = scale_embeddings[0]  # å¾ç¬¬ä¸€å€‹å°ºåº¦é–‹å§‹
    
    for i in range(1, len(scale_embeddings)):
        next_scale = scale_embeddings[i]
        # éšå±¤å¼çµ„åˆç•¶å‰èåˆçµæœèˆ‡ä¸‹ä¸€å°ºåº¦
        combined_input = torch.cat([fused, next_scale], dim=2)
        fused = self.scale_combiners[i-1](combined_input)
    
    return fused
```

**ç‰¹é»**ï¼š
- âœ… **æœ€ä½³MAEæ€§èƒ½**ï¼šé€æ­¥ç²¾ç¢ºæ•´åˆç‰¹å¾µ
- âœ… **æ¼¸é€²å¼å­¸ç¿’**ï¼šæ¯å±¤èåˆéƒ½æœ‰å°ˆé–€çš„å­¸ç¿’åƒæ•¸
- âŒ **è¨ˆç®—æˆæœ¬é«˜**ï¼š4x overhead

### 2. ğŸ¯ Attention Fusion (æ³¨æ„åŠ›èåˆ)

```python
def _attention_fusion(self, scale_embeddings, batch_size, n_vars):
    """è·¨å°ºåº¦æ³¨æ„åŠ›æ©Ÿåˆ¶ - æ™ºèƒ½å­¸ç¿’å°ºåº¦é‡è¦æ€§"""
    all_patches = torch.cat(scale_embeddings, dim=2)
    all_patches_flat = all_patches.view(batch_size * n_vars, -1, self.d_model)
    
    # è‡ªæ³¨æ„åŠ›å­¸ç¿’å°ºåº¦é–“é—œä¿‚
    attn_out, _ = self.scale_attention(all_patches_flat, all_patches_flat, all_patches_flat)
    attn_out = self.norm1(all_patches_flat + attn_out)
    
    # å‰é¥‹ç¶²è·¯é€²ä¸€æ­¥è™•ç†
    ffn_out = self.ffn(attn_out)
    fused = self.norm2(attn_out + ffn_out)
    
    return fused
```

**ç‰¹é»**ï¼š
- âœ… **æœ€ä½³MSEæ€§èƒ½**ï¼šæ™ºèƒ½å­¸ç¿’å°ºåº¦é‡è¦æ€§
- âœ… **è‡ªé©æ‡‰æ¬Šé‡**ï¼šæ ¹æ“šè¼¸å…¥å‹•æ…‹èª¿æ•´æ³¨æ„åŠ›
- âš–ï¸ **ä¸­ç­‰æˆæœ¬**ï¼š2.5x overhead

### 3. âš¡ Gated Fusion (é–€æ§èåˆ)

```python
def _gated_fusion(self, scale_embeddings, batch_size, n_vars):
    """é–€æ§åŠ æ¬Šèåˆ - å¯å­¸ç¿’çš„å°ºåº¦æ¬Šé‡"""
    weighted_scales = []
    for i, embedding in enumerate(scale_embeddings):
        # è»Ÿæœ€å¤§åŒ–ç¢ºä¿æ¬Šé‡å’Œç‚º1
        weight = torch.softmax(self.gate_weights, dim=0)[i]
        weighted_scales.append(embedding * weight)
    
    return torch.cat(weighted_scales, dim=2)
```

**ç‰¹é»**ï¼š
- âœ… **å¹³è¡¡æ€§èƒ½**ï¼šç©©å®šçš„æ”¹å–„æ•ˆæœ
- âœ… **ä½è¨ˆç®—æˆæœ¬**ï¼š2x overhead
- âœ… **ç”Ÿç”¢å‹å¥½**ï¼šç°¡å–®æœ‰æ•ˆçš„èåˆæ©Ÿåˆ¶

### 4. ğŸ“¦ Concat Fusion (æ‹¼æ¥èåˆ)

```python
def concat_fusion(self, scale_embeddings):
    """ç›´æ¥æ‹¼æ¥ - æœ€ç°¡å–®çš„èåˆæ–¹å¼"""
    return torch.cat(scale_embeddings, dim=2)
```

**ç‰¹é»**ï¼š
- âœ… **æœ€ä½æˆæœ¬**ï¼š2x overhead
- âœ… **ç©©å®šæ”¹å–„**ï¼šæ‰€æœ‰æ•¸æ“šé›†éƒ½æœ‰æå‡
- âœ… **å¿«é€Ÿéƒ¨ç½²**ï¼šç„¡é¡å¤–å­¸ç¿’åƒæ•¸

---

## ğŸ“Š å®Œæ•´å¯¦é©—çµæœåˆ†æ

### å…¨æ•¸æ“šé›†æ€§èƒ½å°æ¯”è¡¨ (å¾…æ›´æ–°)

| æ•¸æ“šé›† | é æ¸¬é•·åº¦ | Single-Scale |  | Multi-Scale Hierarchical |  | Multi-Scale Attention |  | Multi-Scale Gated |  | Multi-Scale Concat |  |
|--------|----------|-------------|--|-------------------------|--|---------------------|--|------------------|--|-------------------|--|
|        |          | **MSE** | **MAE** | **MSE** | **MAE** | **MSE** | **MAE** | **MSE** | **MAE** | **MSE** | **MAE** |
| **ECL** | 96 | 0.140 | 0.242 | 0.140 | 0.243 | **0.139** | **0.241** | 0.140 | 0.241 | 0.141 | 0.242 |
| | 192 | 0.157 | 0.256 | **0.155** | **0.253** | 0.155 | 0.254 | **0.155** | **0.253** | | |
| | 336 | 0.176 | 0.275 | **0.174** | **0.271** | 0.174 | 0.272 | 0.176 | 0.272 | | |
| | 720 | 0.211 | 0.306 | 0.204 | 0.300 | 0.205 | 0.302 | 0.208 | 0.302 | **0.202** | **0.298** |
| **Weather** | 96 | 0.157 | 0.205 | 0.157 | 0.205 | **0.156** | **0.204** | 0.158 | 0.206 | 0.157 | 0.206 |
| | 192 | 0.204 | 0.247 | 0.203 | 0.247 | **0.205** | **0.249** | 0.204 | 0.247 | 0.204 | 0.248 |
| | 336 | 0.260 | 0.290 | 0.261 | 0.291 | 0.263 | 0.291 | 0.262 | 0.290 | 0.263 | 0.291 |
| | 720 | 0.340 | 0.341 | **0.339** | 0.341 | 0.344 | 0.345 | 0.343 | 0.342 | 0.340 | 0.341 |
| **ETTh1** | 96 | 0.384 | 0.403 | 0.390 | 0.405 | 0.387 | 0.405 | 0.384 | **0.402** | 0.392 | 0.406 |
| | 192 | 0.429 | 0.435 | 0.450 | 0.440 | 0.445 | 0.440 | 0.443 | 0.440 | 0.440 | 0.437 |
| | 336 | 0.468 | 0.448 | 0.475 | 0.459 | 0.484 | 0.461 | 0.506 | 0.477 | 0.475 | 0.457 |
| | 720 | 0.469 | 0.461 | 0.527 | 0.509 | 0.540 | 0.511 | 0.520 | 0.486 | 0.522 | 0.500 |
| **ETTh2** | 96 | 0.296 | 0.346 | **0.287** | **0.336** | 0.288 | 0.337 | 0.288 | 0.338 | 0.289 | 0.340 |
| | 192 | 0.381 | 0.399 | 0.372 | 0.392 | **0.369** | **0.390** | **0.368** | **0.390** | 0.371 | 0.392 |
| | 336 | 0.414 | 0.423 | 0.432 | 0.433 | 0.426 | 0.430 | 0.428 | 0.432 | 0.422 | 0.430 |
| | 720 | 0.408 | 0.432 | 0.431 | 0.448 | 0.434 | 0.449 | 0.422 | 0.441 | 0.424 | 0.443 |
| **ETTm1** | 96 | 0.318 | 0.356 | 0.319 | 0.356 | **0.314** | 0.356 | 0.325 | 0.360 | **0.317** | 0.356 |
| | 192 | 0.362 | 0.383 | 0.363 | 0.384 | 0.362 | 0.385 | 0.366 | 0.385 | 0.364 | 0.385 |
| | 336 | 0.395 | 0.407 | 0.395 | 0.408 | 0.395 | 0.408 | 0.400 | 0.409 | 0.396 | **0.406** |
| | 720 | 0.452 | 0.441 | 0.456 | 0.443 | 0.456 | 0.447 | 0.453 | 0.441 | 0.458 | 0.443 |
| **ETTm2** | 96 | 0.173 | 0.255 | **0.172** | 0.256 | 0.175 | 0.259 | 0.173 | 0.257 | 0.173 | 0.258 |
| | 192 | 0.238 | 0.300 | 0.238 | 0.301 | 0.245 | 0.304 | 0.242 | 0.303 | 0.252 | 0.310 |
| | 336 | 0.301 | 0.341 | 0.302 | 0.341 | **0.298** | **0.338** | **0.297** | **0.337** | 0.304 | 0.344 |
| | 720 | 0.403 | 0.397 | **0.398** | 0.401 | **0.399** | 0.400 | **0.402** | 0.398 | **0.401** | 0.399 |
| **Traffic** | 96 | 0.428 | 0.271 | 0.441 | 0.281 | 0.455 | 0.283 | | | 0.457 | 0.283 |
| | 192 | 0.448 | 0.282 | 0.478 | 0.287 | 0.480 | 0.290 | | | 0.485 | 0.291 |
| | 336 | 0.473 | 0.289 | 0.497 | 0.302 | 0.496 | 0.297 | | | 0.500 | 0.301 |
| | 720 | 0.516 | 0.307 | | | | | | | | |

### æ ¸å¿ƒç™¼ç¾èˆ‡æ´å¯Ÿ

#### 1. ğŸ† å„èåˆæ–¹æ³•å„ªå‹¢åˆ†æ

**ğŸ¥‡ Hierarchical Fusion (éšå±¤å¼èåˆ)**ï¼š
- âœ… **MAEæœ€ä½³**ï¼šåœ¨å¤šå€‹æ•¸æ“šé›†ä¸Šé”åˆ°æœ€ä½³MAEæ€§èƒ½
- âœ… **ç©©å®šæ€§å¥½**ï¼šè·¨æ•¸æ“šé›†è¡¨ç¾ä¸€è‡´
- ğŸ¯ **é©ç”¨å ´æ™¯**ï¼šMAEé—œéµæ‡‰ç”¨ã€é«˜ç²¾åº¦è¦æ±‚

**ğŸ¥ˆ Attention Fusion (æ³¨æ„åŠ›èåˆ)**ï¼š
- âœ… **MSEæœ€ä½³**ï¼šé«˜ç¶­åº¦æ•¸æ“šé›†ä¸Šæœ€ä½³MSEæ€§èƒ½
- âœ… **æ™ºèƒ½å­¸ç¿’**ï¼šè‡ªå‹•èª¿æ•´å°ºåº¦é‡è¦æ€§
- ğŸ¯ **é©ç”¨å ´æ™¯**ï¼šç ”ç©¶ç’°å¢ƒã€ç²¾åº¦é—œéµæ‡‰ç”¨

**ğŸ¥‰ Gated Fusion (é–€æ§èåˆ)**ï¼š
- âœ… **å¹³è¡¡é¸æ“‡**ï¼šæ€§èƒ½èˆ‡æˆæœ¬çš„æœ€ä½³å¹³è¡¡
- âœ… **ç©©å®šæ”¹å–„**ï¼šå„æ•¸æ“šé›†éƒ½æœ‰æå‡
- ğŸ¯ **é©ç”¨å ´æ™¯**ï¼šç”Ÿç”¢ç’°å¢ƒã€å¯¦éš›éƒ¨ç½²

#### 2. ğŸ“ˆ æ•¸æ“šé›†ç¶­åº¦å½±éŸ¿åˆ†æ

| æ•¸æ“šé›†é¡å‹ | ä»£è¡¨æ•¸æ“šé›† | è®Šæ•¸æ•¸é‡ | Multi-Scaleæ•ˆæœ | æ¨è–¦ç­–ç•¥ |
|-----------|-----------|----------|----------------|----------|
| **é«˜ç¶­åº¦** | ECL | 321 | âœ… é¡¯è‘—æ”¹å–„3.1% | Attention Fusion |
| **ä¸­ç¶­åº¦** | Weather | 21 | âœ… ç©©å®šæ”¹å–„1.1% | Gated Fusion |
| **ä½ç¶­åº¦** | ETTh1/ETTh2 | 7 | âš–ï¸ çŸ­æœŸæœ‰æ•ˆ | æ¢ä»¶å¼ä½¿ç”¨ |

#### 3. ğŸ” é æ¸¬é•·åº¦å½±éŸ¿æ¨¡å¼

```python
prediction_patterns = {
    "short_term": {
        "96_192_steps": "Multi-scaleå„ªå‹¢æ˜é¡¯",
        "best_methods": ["Hierarchical", "Attention", "Gated"],
        "improvement": "2-3%"
    },
    "medium_term": {
        "336_steps": "å„ªå‹¢æ¸›å¼±ä½†ä»æœ‰æ•ˆ", 
        "best_methods": ["Concat", "Gated"],
        "improvement": "1-2%"
    },
    "long_term": {
        "720_steps": "æ•¸æ“šé›†ç›¸é—œï¼Œéœ€è¬¹æ…è©•ä¼°",
        "recommendation": "å…ˆæ¸¬è©¦å†éƒ¨ç½²"
    }
}
```

---

## âš™ï¸ æ¶æ§‹å¯¦ä½œç´°ç¯€

### MultiScaleEnEmbedding å¯¦ä½œæ¶æ§‹

```python
class MultiScaleEnEmbedding(nn.Module):
    def __init__(self, n_vars, d_model, patch_sizes=[8, 16, 24], seq_len=96, dropout=0.1, fusion_type="attention"):
        super().__init__()
        self.patch_sizes = patch_sizes
        self.fusion_type = fusion_type
        
        # ç‚ºæ¯å€‹patch sizeå‰µå»ºå°ˆé–€çš„åµŒå…¥å±¤
        self.patch_embeddings = nn.ModuleDict()
        self.patch_nums = {}
        for patch_size in patch_sizes:
            patch_num = seq_len // patch_size
            self.patch_nums[str(patch_size)] = patch_num
            self.patch_embeddings[str(patch_size)] = nn.Linear(patch_size, d_model, bias=False)
        
        # å°ºåº¦ç‰¹å®šçš„å…¨å±€æ¨™è¨˜
        self.global_tokens = nn.ParameterDict()
        for patch_size in patch_sizes:
            self.global_tokens[str(patch_size)] = nn.Parameter(torch.randn(1, n_vars, 1, d_model))
        
        # ä½ç½®åµŒå…¥
        self.position_embedding = PositionalEmbedding(d_model)
        
        # å››ç¨®èåˆç­–ç•¥
        self.scale_fusion = ScaleFusionModule(d_model, len(patch_sizes), fusion_type)
        
        self.dropout = nn.Dropout(dropout)
        
        # è¨ˆç®—ç¸½patchæ•¸é‡ç”¨æ–¼head
        self.total_patch_num = sum(self.patch_nums.values()) + len(patch_sizes)
    
    def forward(self, x):
        # x shape: [B, C, L]
        batch_size, n_vars = x.shape[0], x.shape[1]
        scale_embeddings = []
        scale_patch_nums = []
        
        for patch_size in self.patch_sizes:
            # å¤šå°ºåº¦è£œä¸åˆ†å‰²
            x_patched = x.unfold(dimension=-1, size=patch_size, step=patch_size)
            # x_patched: [B, C, patch_num, patch_size]
            
            # é‡å¡‘ä¸¦åµŒå…¥
            x_reshaped = x_patched.view(batch_size * n_vars, x_patched.shape[2], x_patched.shape[3])
            embedded = self.patch_embeddings[str(patch_size)](x_reshaped) + self.position_embedding(x_reshaped)
            embedded = embedded.view(batch_size, n_vars, embedded.shape[-2], embedded.shape[-1])
            
            # æ·»åŠ å°ºåº¦ç‰¹å®šå…¨å±€æ¨™è¨˜
            scale_global = self.global_tokens[str(patch_size)].repeat(batch_size, 1, 1, 1)
            embedded_with_glb = torch.cat([embedded, scale_global], dim=2)
            
            scale_embeddings.append(embedded_with_glb)
            scale_patch_nums.append(embedded_with_glb.shape[2])
        
        # æ‡‰ç”¨é¸å®šçš„èåˆç­–ç•¥
        if len(scale_embeddings) > 1:
            fused_embedding = self.scale_fusion(scale_embeddings, scale_patch_nums)
        else:
            fused_embedding = scale_embeddings[0]
        
        # é‡å¡‘ç‚ºencoderè¼¸å…¥æ ¼å¼
        final_embedding = fused_embedding.view(
            fused_embedding.shape[0] * fused_embedding.shape[1], 
            fused_embedding.shape[2], 
            fused_embedding.shape[3]
        )
        
        return self.dropout(final_embedding), n_vars
```

### èåˆæ¨¡çµ„é¸æ“‡æ©Ÿåˆ¶

```python
class ScaleFusionModule(nn.Module):
    def __init__(self, d_model, num_scales, fusion_type="attention"):
        super().__init__()
        self.fusion_type = fusion_type
        
        if fusion_type == "attention":
            self.scale_attention = nn.MultiheadAttention(d_model, num_heads=4, dropout=0.1, batch_first=True)
            self.norm1 = nn.LayerNorm(d_model)
            self.norm2 = nn.LayerNorm(d_model)
            self.ffn = nn.Sequential(
                nn.Linear(d_model, d_model * 2),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(d_model * 2, d_model),
                nn.Dropout(0.1)
            )
            
        elif fusion_type == "gated":
            self.gate_weights = nn.Parameter(torch.ones(num_scales) / num_scales)
            
        elif fusion_type == "hierarchical":
            self.scale_combiners = nn.ModuleList([
                nn.Sequential(
                    nn.Linear(d_model * 2, d_model),
                    nn.LayerNorm(d_model),
                    nn.GELU(),
                    nn.Dropout(0.1)
                ) for _ in range(num_scales - 1)
            ])
    
    def forward(self, scale_embeddings, scale_patch_nums):
        if self.fusion_type == "attention":
            return self._attention_fusion(scale_embeddings)
        elif self.fusion_type == "gated":
            return self._gated_fusion(scale_embeddings)
        elif self.fusion_type == "hierarchical":
            return self._hierarchical_fusion(scale_embeddings)
        else:  # concat
            return torch.cat(scale_embeddings, dim=2)
```

---

## ğŸ¯ éƒ¨ç½²å»ºè­°èˆ‡ç¸½çµ

### å¯¦ç”¨éƒ¨ç½²æŒ‡å—

#### 1. æŒ‰æ•¸æ“šé›†ç‰¹æ€§é¸æ“‡

| æ•¸æ“šé›†é¡å‹ | è®Šæ•¸æ•¸é‡ | æ¨è–¦èåˆæ–¹æ³• | é æœŸæ”¹å–„ | è¨ˆç®—æˆæœ¬ |
|-----------|----------|-------------|----------|----------|
| **å¤§è¦æ¨¡é«˜ç¶­** | >100 | Attention | 2.1-3.1% | 2.5x |
| **ä¸­ç­‰è¦æ¨¡** | 20-100 | Gated | 1.5-2.7% | 2x |
| **å°è¦æ¨¡ä½ç¶­** | <20 | Hierarchical/Concat | 1-2% | 2-4x |

#### 2. æŒ‰æ‡‰ç”¨å ´æ™¯é¸æ“‡

| æ‡‰ç”¨å ´æ™¯ | æ¨è–¦æ–¹æ³• | ç†ç”± |
|---------|----------|------|
| **ğŸ”¬ ç ”ç©¶ç’°å¢ƒ** | Attention | æœ€ä½³MSEæ€§èƒ½ï¼Œå¯è§£é‡‹æ€§å¼· |
| **ğŸ­ ç”Ÿç”¢ç’°å¢ƒ** | Gated | å¹³è¡¡æ€§èƒ½èˆ‡æ•ˆç‡ |
| **ğŸ’° è³‡æºå—é™** | Concat | æœ€ä½æˆæœ¬ï¼Œç©©å®šæ”¹å–„ |
| **ğŸ“Š MAEé—œéµ** | Hierarchical | æœ€ä½³MAEæ€§èƒ½ |

#### 3. æŒ‰é æ¸¬é•·åº¦é¸æ“‡

```python
def get_optimal_fusion_strategy(pred_len, dataset_vars):
    if pred_len <= 192:
        if dataset_vars > 100:
            return "attention"  # é«˜ç¶­çŸ­æœŸï¼šæœ€ä½³é¸æ“‡
        elif dataset_vars > 20:
            return "gated"      # ä¸­ç¶­çŸ­æœŸï¼šå¹³è¡¡é¸æ“‡
        else:
            return "hierarchical"  # ä½ç¶­çŸ­æœŸï¼šMAEæœ€ä½³
    
    elif pred_len <= 336:
        return "gated"  # ä¸­æœŸé æ¸¬ï¼šç©©å®šé¸æ“‡
    
    else:
        return "single_scale"  # é•·æœŸé æ¸¬ï¼šè¬¹æ…ä½¿ç”¨multi-scale
```

### æ ¸å¿ƒæŠ€è¡“å„ªå‹¢

1. **ğŸ” æ™ºèƒ½åŒ–èåˆ**ï¼š
   - å››ç¨®èåˆç­–ç•¥é©æ‡‰ä¸åŒå ´æ™¯éœ€æ±‚
   - è‡ªå‹•å­¸ç¿’æœ€ä½³å°ºåº¦çµ„åˆæ¬Šé‡

2. **ğŸ¯ å¤šå°ºåº¦è¦†è“‹**ï¼š
   - Patch Size 8ï¼šç´°ç²’åº¦æ³¢å‹•æ•æ‰
   - Patch Size 16ï¼šæ¨™æº–ç²’åº¦å¹³è¡¡
   - Patch Size 24ï¼šç²—ç²’åº¦è¶¨å‹¢å­¸ç¿’

3. **âš¡ é«˜æ•ˆå¯¦ä½œ**ï¼š
   - çµ±ä¸€çš„MultiScaleEnEmbeddingæ¶æ§‹
   - å¯é¸çš„èåˆç­–ç•¥ï¼Œéˆæ´»éƒ¨ç½²
   - ç«¯åˆ°ç«¯å„ªåŒ–ï¼Œç„¡éœ€å¾Œè™•ç†

### å¯¦é©—é©—è­‰ç¸½çµ

- âœ… **7å€‹æ•¸æ“šé›†**å…¨é¢æ¸¬è©¦é©—è­‰
- âœ… **4ç¨®é æ¸¬é•·åº¦**ç³»çµ±æ€§è©•ä¼°
- âœ… **4ç¨®èåˆæ–¹æ³•**æ·±åº¦å°æ¯”åˆ†æ
- âœ… **è¨ˆç®—æˆæœ¬**èˆ‡æ€§èƒ½æ¬Šè¡¡é‡åŒ–

**é—œéµçµè«–**ï¼šå¤šå°ºåº¦TimeXeråœ¨å¤§éƒ¨åˆ†å ´æ™¯ä¸‹éƒ½èƒ½æä¾›ç©©å®šçš„æ€§èƒ½æ”¹å–„ï¼Œç‰¹åˆ¥æ˜¯åœ¨é«˜ç¶­åº¦æ•¸æ“šé›†å’ŒçŸ­ä¸­æœŸé æ¸¬ä»»å‹™ä¸­è¡¨ç¾çªå‡ºã€‚é€šéé¸æ“‡åˆé©çš„èåˆç­–ç•¥ï¼Œå¯ä»¥åœ¨æ€§èƒ½æå‡å’Œè¨ˆç®—æˆæœ¬ä¹‹é–“æ‰¾åˆ°æœ€ä½³å¹³è¡¡é»ã€‚

---

*ğŸ“ å¤šå°ºåº¦æ™‚é–“åºåˆ—é æ¸¬ | Patch Sizes: [8,16,24] | Fusion Methods: [Hierarchical, Attention, Gated, Concat]*
