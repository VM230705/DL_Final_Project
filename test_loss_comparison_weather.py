#!/usr/bin/env python3
"""
Loss Function Comparison Experiment on Weather Dataset
æ¯”è¼ƒä¸åŒlosså‡½æ•¸åœ¨Weather datasetä¸Šçš„å¯¦éš›è¨“ç·´æ€§èƒ½

æ¸¬è©¦çš„losså‡½æ•¸:
1. MSE (é è¨­)
2. SpikeAwareLoss (åŸºç¤spike-aware loss)
3. AdaptiveSpikeAwareLoss (è‡ªé©æ‡‰spike-aware loss)
4. HybridLoss (æ··åˆloss)
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
import argparse
import time
from datetime import datetime
import json

# Add project root to path
sys.path.append('/home/vm230705/dlp/Project')

from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast
from utils.losses import SpikeAwareLoss, AdaptiveSpikeAwareLoss, HybridLoss
from utils.tools import EarlyStopping, adjust_learning_rate
from utils.metrics import metric

class LossComparisonExperiment:
    """Losså‡½æ•¸æ¯”è¼ƒå¯¦é©—é¡"""
    
    def __init__(self, base_args):
        self.base_args = base_args
        self.results = {}
        self.experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å‰µå»ºå¯¦é©—è¨˜éŒ„ç›®éŒ„
        self.log_dir = f"/home/vm230705/dlp/Project/loss_comparison_logs_{self.experiment_id}"
        os.makedirs(self.log_dir, exist_ok=True)
        
        print(f"ğŸš€ Loss Comparison Experiment Started: {self.experiment_id}")
        print(f"ğŸ“ Logs will be saved to: {self.log_dir}")
    
    def create_loss_functions(self):
        """å‰µå»ºä¸åŒçš„losså‡½æ•¸"""
        loss_functions = {
            # 'MSE': nn.MSELoss(),
            'SpikeAware': SpikeAwareLoss(
                base_loss='mse', 
                spike_weight=2.0, 
                derivative_weight=1.5,
                percentile=85
            ),
            'AdaptiveSpikeAware': AdaptiveSpikeAwareLoss(
                base_loss='mse',
                initial_spike_weight=2.0,
                initial_derivative_weight=1.5
            ),
            'HybridLoss': HybridLoss(
                base_loss='mse',
                alpha=0.7,
                spike_weight=2.0,
                derivative_weight=1.5
            )
        }
        return loss_functions
    
    def run_experiment_with_loss(self, loss_name, loss_function, max_epochs=15):
        """ä½¿ç”¨æŒ‡å®šlosså‡½æ•¸é‹è¡Œå¯¦é©—"""
        print(f"\nğŸ”¬ Testing Loss Function: {loss_name}")
        print("=" * 60)
        
        # è¤‡è£½åŸºç¤åƒæ•¸
        args = argparse.Namespace(**vars(self.base_args))
        args.loss = loss_name
        args.train_epochs = max_epochs
        args.des = f'LossComp_{loss_name}_{self.experiment_id}'
        
        # å‰µå»ºå¯¦é©—å¯¦ä¾‹
        exp = Exp_Long_Term_Forecast(args)
        
        # æ›¿æ›losså‡½æ•¸
        exp._select_criterion = lambda: loss_function
        
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = time.time()
        
        try:
            print(f"ğŸ“Š Training with {loss_name} loss...")
            
            # ç²å–æ•¸æ“šåŠ è¼‰å™¨
            train_data, train_loader = exp._get_data(flag='train')
            vali_data, vali_loader = exp._get_data(flag='val')
            test_data, test_loader = exp._get_data(flag='test')
            
            # è¨“ç·´éç¨‹
            train_metrics = self._custom_train(
                exp, train_loader, vali_loader, test_loader, 
                loss_function, max_epochs, loss_name
            )
            
            # æ¸¬è©¦æœ€çµ‚æ€§èƒ½
            test_metrics = self._evaluate_model(exp, test_loader, loss_function)
            
            training_time = time.time() - start_time
            
            # è¨˜éŒ„çµæœ
            result = {
                'loss_name': loss_name,
                'training_time': training_time,
                'train_metrics': train_metrics,
                'test_metrics': test_metrics,
                'final_train_loss': train_metrics['final_train_loss'],
                'final_val_loss': train_metrics['final_val_loss'],
                'epochs_trained': train_metrics['epochs_trained'],
                'early_stopped': train_metrics['early_stopped']
            }
            
            self.results[loss_name] = result
            
            print(f"âœ… {loss_name} - Training completed!")
            print(f"   ğŸ“ˆ Final Test MSE: {test_metrics['mse']:.6f}")
            print(f"   ğŸ“‰ Final Test MAE: {test_metrics['mae']:.6f}")
            print(f"   â±ï¸  Training Time: {training_time:.2f}s")
            print(f"   ğŸ”„ Epochs: {train_metrics['epochs_trained']}")
            
            # ä¿å­˜è©³ç´°çµæœ
            self._save_result(loss_name, result)
            
            return result
            
        except Exception as e:
            print(f"âŒ Error with {loss_name}: {str(e)}")
            error_result = {
                'loss_name': loss_name,
                'error': str(e),
                'training_time': time.time() - start_time
            }
            self.results[loss_name] = error_result
            return error_result
    
    def _custom_train(self, exp, train_loader, vali_loader, test_loader, criterion, max_epochs, loss_name):
        """è‡ªå®šç¾©è¨“ç·´éç¨‹"""
        model = exp.model
        device = exp.device
        
        # å„ªåŒ–å™¨
        model_optim = exp._select_optimizer()
        
        # Early stopping
        early_stopping = EarlyStopping(patience=3, verbose=True)
        
        train_losses = []
        val_losses = []
        
        for epoch in range(max_epochs):
            model.train()
            epoch_train_loss = []
            
            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):
                model_optim.zero_grad()
                
                batch_x = batch_x.float().to(device)
                batch_y = batch_y.float().to(device)
                batch_x_mark = batch_x_mark.float().to(device)
                batch_y_mark = batch_y_mark.float().to(device)
                
                # Decoder input
                dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()
                dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float().to(device)
                
                # Forward pass
                if exp.args.output_attention:
                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]
                else:
                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
                
                f_dim = -1 if exp.args.features == 'MS' else 0
                outputs = outputs[:, -exp.args.pred_len:, f_dim:]
                batch_y = batch_y[:, -exp.args.pred_len:, f_dim:].to(device)
                
                # è¨ˆç®—loss
                if hasattr(criterion, 'forward'):
                    # å°æ–¼spike-aware lossï¼Œéœ€è¦å‚³å…¥é æ¸¬å’ŒçœŸå¯¦å€¼
                    loss = criterion(outputs, batch_y)
                else:
                    # å°æ–¼æ¨™æº–MSE loss
                    loss = criterion(outputs, batch_y)
                
                epoch_train_loss.append(loss.item())
                
                loss.backward()
                model_optim.step()
            
            # é©—è­‰
            val_loss = self._validate(exp, vali_loader, criterion)
            
            avg_train_loss = np.mean(epoch_train_loss)
            train_losses.append(avg_train_loss)
            val_losses.append(val_loss)
            
            print(f"   Epoch {epoch+1:2d}/{max_epochs} | Train Loss: {avg_train_loss:.6f} | Val Loss: {val_loss:.6f}")
            
            # Early stopping check
            early_stopping(val_loss, model, f"{self.log_dir}")
            if early_stopping.early_stop:
                print(f"   Early stopping at epoch {epoch+1}")
                break
            
            # å­¸ç¿’ç‡èª¿æ•´
            adjust_learning_rate(model_optim, epoch + 1, exp.args)
        
        return {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'final_train_loss': train_losses[-1],
            'final_val_loss': val_losses[-1],
            'epochs_trained': len(train_losses),
            'early_stopped': early_stopping.early_stop
        }
    
    def _validate(self, exp, vali_loader, criterion):
        """é©—è­‰éç¨‹"""
        model = exp.model
        device = exp.device
        
        model.eval()
        total_loss = []
        
        with torch.no_grad():
            for batch_x, batch_y, batch_x_mark, batch_y_mark in vali_loader:
                batch_x = batch_x.float().to(device)
                batch_y = batch_y.float().to(device)
                batch_x_mark = batch_x_mark.float().to(device)
                batch_y_mark = batch_y_mark.float().to(device)
                
                dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()
                dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float().to(device)
                
                if exp.args.output_attention:
                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]
                else:
                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
                
                f_dim = -1 if exp.args.features == 'MS' else 0
                outputs = outputs[:, -exp.args.pred_len:, f_dim:]
                batch_y = batch_y[:, -exp.args.pred_len:, f_dim:].to(device)
                
                # ç‚ºäº†å…¬å¹³æ¯”è¼ƒï¼Œé©—è­‰æ™‚éƒ½ä½¿ç”¨MSE
                loss = nn.MSELoss()(outputs, batch_y)
                total_loss.append(loss.item())
        
        return np.mean(total_loss)
    
    def _evaluate_model(self, exp, test_loader, criterion):
        """è©•ä¼°æ¨¡å‹æœ€çµ‚æ€§èƒ½"""
        model = exp.model
        device = exp.device
        
        model.eval()
        preds = []
        trues = []
        
        with torch.no_grad():
            for batch_x, batch_y, batch_x_mark, batch_y_mark in test_loader:
                batch_x = batch_x.float().to(device)
                batch_y = batch_y.float().to(device)
                batch_x_mark = batch_x_mark.float().to(device)
                batch_y_mark = batch_y_mark.float().to(device)
                
                dec_inp = torch.zeros_like(batch_y[:, -exp.args.pred_len:, :]).float()
                dec_inp = torch.cat([batch_y[:, :exp.args.label_len, :], dec_inp], dim=1).float().to(device)
                
                if exp.args.output_attention:
                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]
                else:
                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
                
                f_dim = -1 if exp.args.features == 'MS' else 0
                outputs = outputs[:, -exp.args.pred_len:, f_dim:]
                batch_y = batch_y[:, -exp.args.pred_len:, f_dim:].to(device)
                
                preds.append(outputs.detach().cpu().numpy())
                trues.append(batch_y.detach().cpu().numpy())
        
        preds = np.concatenate(preds, axis=0)
        trues = np.concatenate(trues, axis=0)
        
        # è¨ˆç®—æ¨™æº–metrics
        mae, mse, rmse, mape, mspe = metric(preds, trues)
        
        return {
            'mae': mae,
            'mse': mse,
            'rmse': rmse,
            'mape': mape,
            'mspe': mspe
        }
    
    def _save_result(self, loss_name, result):
        """ä¿å­˜å¯¦é©—çµæœ"""
        result_file = os.path.join(self.log_dir, f"{loss_name}_result.json")
        with open(result_file, 'w') as f:
            # è½‰æ›numpyé¡å‹ç‚ºPythonåŸç”Ÿé¡å‹
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, (np.integer, np.floating)):
                    return obj.item()
                elif isinstance(obj, dict):
                    return {k: convert_numpy(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(item) for item in obj]
                return obj
            
            json.dump(convert_numpy(result), f, indent=2)
    
    def run_all_experiments(self):
        """é‹è¡Œæ‰€æœ‰losså‡½æ•¸çš„æ¯”è¼ƒå¯¦é©—"""
        print(f"ğŸ”¬ Starting Comprehensive Loss Function Comparison")
        print(f"ğŸ“Š Dataset: Weather (21 variables, 96-step forecasting)")
        print("=" * 80)
        
        loss_functions = self.create_loss_functions()
        
        for loss_name, loss_func in loss_functions.items():
            try:
                self.run_experiment_with_loss(loss_name, loss_func)
                # æ¸…ç†GPUç·©å­˜
                torch.cuda.empty_cache()
                time.sleep(2)  # çµ¦ç³»çµ±ä¸€äº›ä¼‘æ¯æ™‚é–“
            except Exception as e:
                print(f"âŒ Failed to run experiment with {loss_name}: {str(e)}")
                continue
        
        # ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
        self.generate_comparison_report()
    
    def generate_comparison_report(self):
        """ç”Ÿæˆæ¯”è¼ƒå ±å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ LOSS FUNCTION COMPARISON REPORT")
        print("=" * 80)
        
        if not self.results:
            print("âŒ No results to compare")
            return
        
        # å‰µå»ºæ¯”è¼ƒè¡¨æ ¼
        print(f"{'Loss Function':<20} {'Test MSE':<12} {'Test MAE':<12} {'Time(s)':<10} {'Epochs':<8} {'Early Stop':<12}")
        print("-" * 80)
        
        best_mse = float('inf')
        best_mae = float('inf')
        best_loss_mse = ""
        best_loss_mae = ""
        
        for loss_name, result in self.results.items():
            if 'error' in result:
                print(f"{loss_name:<20} {'ERROR':<12} {'ERROR':<12} {result['training_time']:<10.1f} {'N/A':<8} {'N/A':<12}")
                continue
            
            test_mse = result['test_metrics']['mse']
            test_mae = result['test_metrics']['mae']
            training_time = result['training_time']
            epochs = result['epochs_trained']
            early_stop = 'Yes' if result['early_stopped'] else 'No'
            
            print(f"{loss_name:<20} {test_mse:<12.6f} {test_mae:<12.6f} {training_time:<10.1f} {epochs:<8} {early_stop:<12}")
            
            if test_mse < best_mse:
                best_mse = test_mse
                best_loss_mse = loss_name
            
            if test_mae < best_mae:
                best_mae = test_mae
                best_loss_mae = loss_name
        
        print("\nğŸ† WINNERS:")
        print(f"   Best MSE: {best_loss_mse} ({best_mse:.6f})")
        print(f"   Best MAE: {best_loss_mae} ({best_mae:.6f})")
        
        # ä¿å­˜å®Œæ•´å ±å‘Š
        report_file = os.path.join(self.log_dir, "comparison_report.json")
        with open(report_file, 'w') as f:
            def convert_numpy(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, (np.integer, np.floating)):
                    return obj.item()
                elif isinstance(obj, dict):
                    return {k: convert_numpy(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy(item) for item in obj]
                return obj
                
            json.dump({
                'experiment_id': self.experiment_id,
                'best_mse_loss': best_loss_mse,
                'best_mse_value': best_mse,
                'best_mae_loss': best_loss_mae,
                'best_mae_value': best_mae,
                'results': convert_numpy(self.results)
            }, f, indent=2)
        
        print(f"\nğŸ“ Full results saved to: {self.log_dir}")

def create_weather_args():
    """å‰µå»ºWeather datasetçš„å¯¦é©—åƒæ•¸"""
    args = argparse.Namespace()
    
    # åŸºæœ¬è¨­ç½®
    args.task_name = 'long_term_forecast'
    args.is_training = 1
    args.model_id = 'weather_96_96_loss_comparison'
    args.model = 'TimeXer'
    args.data = 'custom'
    args.root_path = './dataset/weather/'
    args.data_path = 'weather.csv'
    args.features = 'M'
    
    # åºåˆ—åƒæ•¸
    args.seq_len = 96
    args.label_len = 48
    args.pred_len = 96
    
    # æ¨¡å‹åƒæ•¸ (åŸºæ–¼Weather datasetçš„æœ€ä½³é…ç½®)
    args.d_model = 256
    args.d_ff = 512
    args.n_heads = 8
    args.e_layers = 1
    args.d_layers = 1
    args.factor = 3
    args.enc_in = 21
    args.dec_in = 21
    args.c_out = 21
    
    # è¨“ç·´åƒæ•¸
    args.batch_size = 4
    args.learning_rate = 0.0001
    args.train_epochs = 10
    args.patience = 3
    args.use_amp = False
    args.lradj = 'type1'
    
    # å…¶ä»–åƒæ•¸
    args.embed = 'timeF'
    args.freq = 't'
    args.dropout = 0.1
    args.des = 'LossComparison'
    args.use_gpu = True
    args.gpu = 0
    args.use_multi_gpu = False
    args.devices = '0'
    args.checkpoints = './checkpoints/'
    args.output_attention = False
    args.inverse = False
    
    # TimeXerç‰¹å®šåƒæ•¸
    args.patch_len = 16
    args.use_multi_scale = False
    args.use_norm = True  # æ·»åŠ ç¼ºå¤±çš„åƒæ•¸
    args.activation = 'gelu'  # æ·»åŠ æ¿€æ´»å‡½æ•¸åƒæ•¸
    
    # æ–°å¢å…¶ä»–å¿…è¦åƒæ•¸
    args.target = 'OT'
    args.seasonal_patterns = 'Monthly'
    args.num_workers = 0
    args.itr = 1
    args.loss = 'MSE'
    args.expand = 2
    args.d_conv = 4
    args.distil = True
    args.augmentation_ratio = 0  # æ·»åŠ æ•¸æ“šå¢å¼·åƒæ•¸ï¼Œè¨­ç‚º0è¡¨ç¤ºä¸ä½¿ç”¨å¢å¼·
    
    return args

def main():
    print("ğŸš€ Loss Function Comparison Experiment for Weather Dataset")
    print("ğŸ“Š Testing: MSE vs SpikeAware vs AdaptiveSpikeAware vs HybridLoss")
    
    # è¨­ç½®éš¨æ©Ÿç¨®å­
    torch.manual_seed(2021)
    np.random.seed(2021)
    
    # å‰µå»ºå¯¦é©—åƒæ•¸
    args = create_weather_args()
    
    # å‰µå»ºä¸¦é‹è¡Œå¯¦é©—
    experiment = LossComparisonExperiment(args)
    experiment.run_all_experiments()

if __name__ == "__main__":
    main()